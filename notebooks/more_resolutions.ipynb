{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')\n",
    "from features import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbit_rate = 1/125000\n",
    "\n",
    "low_fp = '../data/240p/' \n",
    "threesixty_fp = '../data/360p/' \n",
    "med_fp = '../data/480p/'\n",
    "seventwenty_fp = '../data/720p/' \n",
    "high_fp = '../data/1080p/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dfs = []\n",
    "for file in os.listdir(low_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        low_dfs.append(pd.read_csv(low_fp+file))\n",
    "    \n",
    "threesixty_dfs = []\n",
    "for file in os.listdir(threesixty_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        threesixty_dfs.append(pd.read_csv(threesixty_fp+file))\n",
    "        \n",
    "med_dfs = []\n",
    "for file in os.listdir(med_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        med_dfs.append(pd.read_csv(med_fp+file))\n",
    "        \n",
    "seventwenty_dfs = []\n",
    "for file in os.listdir(seventwenty_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        seventwenty_dfs.append(pd.read_csv(seventwenty_fp+file))\n",
    "    \n",
    "high_dfs = []\n",
    "for file in os.listdir(high_fp):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        high_dfs.append(pd.read_csv(high_fp+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdoan_low = pd.read_csv(low_fp + 'stdoan-101-action-240p-20201127.csv')\n",
    "# stdoan_med = pd.read_csv(med_fp + 'stdoan-101-action-480p-20201127.csv')\n",
    "# stdoan_high = pd.read_csv(high_fp + 'stdoan-101-action-1080p-20201127.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ms = []\n",
    "for df in low_dfs:\n",
    "    low_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "threesixty_ms = []\n",
    "for df in threesixty_dfs:\n",
    "    threesixty_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "med_ms = []\n",
    "for df in med_dfs:\n",
    "    med_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "seventwenty_ms = []\n",
    "for df in seventwenty_dfs:\n",
    "    seventwenty_ms.append(convert_ms_df(df,True))\n",
    "    \n",
    "high_ms = []\n",
    "for df in high_dfs:\n",
    "    high_ms.append(convert_ms_df(df,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_ms = convert_ms_df(stdoan_low, True)\n",
    "# med_ms = convert_ms_df(stdoan_med, True)\n",
    "# high_ms = convert_ms_df(stdoan_high, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_resamples = []\n",
    "for df in low_ms:\n",
    "    low_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "threesixty_resamples = []\n",
    "for df in threesixty_ms:\n",
    "    threesixty_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "med_resamples = []\n",
    "for df in med_ms:\n",
    "    med_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "seventwenty_resamples = []\n",
    "for df in seventwenty_ms:\n",
    "    seventwenty_resamples.append(df.resample('500ms', on='Time').sum())\n",
    "    \n",
    "high_resamples = []\n",
    "for df in high_ms:\n",
    "    high_resamples.append(df.resample('500ms', on='Time').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_resample = low_ms.resample('500ms', on='Time').sum()\n",
    "# med_resample = med_ms.resample('500ms', on='Time').sum()\n",
    "# high_resample = high_ms.resample('500ms', on='Time').sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take the aggregate features of the whole chunk; download and upload\n",
    "def agg_feat(df, col):\n",
    "    return [np.mean(df[col]), np.std(df[col])]\n",
    "\n",
    "## take the ratio of upload:download packets\n",
    "def pkt_ratio(df):\n",
    "    ms_df = convert_ms_df(df, True)\n",
    "    local = np.sum(ms_df['pkt_src'] == '1') \n",
    "    server = np.sum(ms_df['pkt_src'] == '2') \n",
    "    return local / server\n",
    "\n",
    "## take the ratio of upload:download bytes\n",
    "def bytes_ratio(df):\n",
    "    local = df['1->2Bytes'].sum()\n",
    "    server = df['2->1Bytes'].sum()\n",
    "    return local / server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Related Aggregate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finds the peaks with mean + 2(1) std\n",
    "## run the above aggregate functions on the peaks only??\n",
    "\n",
    "def get_peak_loc(df, col, invert=False):\n",
    "  'invert arg allows you to get values not considered peaks'\n",
    "  df_avg = df[col].mean()\n",
    "  df_std = df[col].std()\n",
    "  \n",
    "  threshold = df_avg + (1 * df_std)\n",
    "  \n",
    "  if invert:\n",
    "    return np.array(df[col] < threshold)\n",
    "  \n",
    "  else:\n",
    "    return np.array(df[col] > threshold)\n",
    "\n",
    "## np.mean, np.var, np.std - think of more?  \n",
    "def peak_time_diff(df, col):\n",
    "  '''\n",
    "  mess around with the different inputs for function. \n",
    "  variance seems to inflate the difference betweent the two the most with litte\n",
    "  to no data manipulation. however, currently trying things like\n",
    "  squaring the data before taking the aggregate function to exaggerate\n",
    "  differences (moderate success??)\n",
    "  '''\n",
    "  peaks = df[get_peak_loc(df, col)]\n",
    "  peaks['Time'] = peaks['Time'] - peaks['Time'].min()\n",
    "  time_diff = np.diff(peaks['Time'] ** 2)\n",
    "  return [np.mean(time_diff), np.std(time_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def peak_times(df,col,thresh):\n",
    "    x = df[col]\n",
    "    peaks, _ = find_peaks(x, height=thresh)\n",
    "    if list(peaks) == []:\n",
    "        return [-1]\n",
    "    times = df.iloc[peaks]['Time'].values\n",
    "    time_between_peaks = [times[i]-times[i-1]for i in range(1,len(times))]\n",
    "    #print(time_between_peaks)\n",
    "    #time_between_peaks[0]=0\n",
    "    if time_between_peaks == []:\n",
    "        return -1\n",
    "    return time_between_peaks\n",
    "\n",
    "def num_peaks(df,col,thresh):\n",
    "    x = df[col]\n",
    "    peaks, _ = find_peaks(x, height=thresh)\n",
    "    return len(peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_features(df, col):\n",
    "\n",
    "    \"\"\"\n",
    "    welch implemention of spectral features\n",
    "    resample the data before inputting (might change prereq depending on\n",
    "    resource allocation)\n",
    "    \"\"\"\n",
    "\n",
    "    f, Pxx_den = sp.signal.welch(df[col], fs=2)\n",
    "    Pxx_den = np.sqrt(Pxx_den)\n",
    "\n",
    "    peaks = sp.signal.find_peaks(Pxx_den)[0]\n",
    "    prominences = sp.signal.peak_prominences(Pxx_den, peaks)[0]\n",
    "\n",
    "    idx_max = prominences.argmax()\n",
    "    loc_max = peaks[idx_max]\n",
    "\n",
    "    return [f[loc_max], Pxx_den[loc_max], prominences[idx_max]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking & Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wip; need to decide chunk size eventually\n",
    "## should we also make this chunking feature be our feature creation?\n",
    "\n",
    "def chunk_data(df, interval=60):\n",
    "\n",
    "    \"\"\"\n",
    "    takes in a filepath to the data you want to chunk and feature engineer\n",
    "    chunks our data into a specified time interval\n",
    "    each chunk is then turned into an observation to be fed into our classifier\n",
    "    \"\"\"\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    df['Time'] = df['Time'] - df['Time'].min()\n",
    "    \n",
    "    total_chunks = np.floor(df['Time'].max() / interval).astype(int)\n",
    "\n",
    "    for chunk in np.arange(total_chunks):\n",
    "      \n",
    "        start = chunk * interval\n",
    "        end = (chunk+1) * interval\n",
    "\n",
    "        temp_df = (df[(df['Time'] >= start) & (df['Time'] < end)])\n",
    "        \n",
    "        df_list.append(temp_df)\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(dfs, interval=60):\n",
    "\n",
    "  features = [\n",
    "    'dwl_peak_freq',\n",
    "    'dwl_peak_prom',\n",
    "    'dwl_max_psd',\n",
    "    'dwl_bytes_avg',\n",
    "    'dwl_bytes_std',\n",
    "    'dwl_peak_avg',\n",
    "    'dwl_peak_std',\n",
    "    'upl_peak_freq',\n",
    "    'upl_peak_prom',\n",
    "    'upl_max_psd',\n",
    "    'upl_bytes_avg',\n",
    "    'upl_bytes_std',\n",
    "    'upl_peak_avg',\n",
    "    'upl_peak_std',\n",
    "    'dwl_time_peak',#'IMAN_up_time_peak',\n",
    "      'dwl_num_peak'#,'IMAN_up_num_peak'\n",
    "  ]  \n",
    "\n",
    "  vals = []\n",
    "  for df in dfs:\n",
    "      df_chunks = chunk_data(df, interval)\n",
    "\n",
    "      for chunk in df_chunks:\n",
    "\n",
    "        preproc = convert_ms_df(chunk, True)\n",
    "        upl_bytes = preproc[preproc['pkt_src'] == '1'].resample('500ms', on='Time').sum()\n",
    "        dwl_bytes = preproc[preproc['pkt_src'] == '2'].resample('500ms', on='Time').sum()\n",
    "\n",
    "        ## spectral features\n",
    "        dwl_spectral = spectral_features(dwl_bytes, 'pkt_size')\n",
    "        upl_spectral = spectral_features(upl_bytes, 'pkt_size')\n",
    "\n",
    "        ## aggregate features\n",
    "        dwl_agg = agg_feat(chunk, '2->1Bytes')\n",
    "        upl_agg = agg_feat(chunk, '1->2Bytes')\n",
    "\n",
    "        ## peak features\n",
    "        dwl_peak = peak_time_diff(chunk, '2->1Bytes')\n",
    "        upl_peak = peak_time_diff(chunk, '1->2Bytes')\n",
    "        \n",
    "        ## iman's time between peak \n",
    "        iman_dwn_time_peak = np.mean(peak_times(chunk,'2->1Bytes',1000000))\n",
    "        #iman_up_time_peak = np.mean(peak_times(chunk,'1->2Bytes',50000))\n",
    "        \n",
    "        ## iman's num peak\n",
    "        iman_dwn_num_peak = num_peaks(chunk,'2->1Bytes',1000000)\n",
    "        #iman_up_num_peak = num_peaks(chunk,'1->2Bytes',50000)\n",
    "\n",
    "\n",
    "        \n",
    "        feat_val = np.hstack((\n",
    "          dwl_spectral,\n",
    "          dwl_agg,\n",
    "          dwl_peak,\n",
    "          upl_spectral,\n",
    "          upl_agg,\n",
    "          upl_peak,\n",
    "            iman_dwn_time_peak,#iman_up_time_peak,\n",
    "            iman_dwn_num_peak,#iman_up_num_peak\n",
    "        ))\n",
    "\n",
    "        vals.append(feat_val)\n",
    "    \n",
    "  return pd.DataFrame(columns=features, data=vals).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.6 s, sys: 468 ms, total: 29.1 s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "low_feat = create_features(low_dfs, 100)\n",
    "threesixty_feat = create_features(threesixty_dfs, 100)\n",
    "med_feat = create_features(med_dfs, 100)\n",
    "seventwenty_feat = create_features(seventwenty_dfs, 100)\n",
    "high_feat = create_features(high_dfs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_feat['resolution'] = '240p'\n",
    "threesixty_feat['resolution'] = '360p'\n",
    "med_feat['resolution'] = '480p'\n",
    "seventwenty_feat['resolution'] = '720p'\n",
    "high_feat['resolution'] = '1080p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([low_feat, threesixty_feat, med_feat,seventwenty_feat, high_feat]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SELECT SUBSETS OF FEATURES\n",
    "\n",
    "#training = training[['dwl_bytes_avg','dwl_peak_prom','upl_bytes_std','dwl_bytes_std','upl_peak_std','resolution']]\n",
    "#training = training[['dwl_bytes_avg','upl_max_psd','dwl_max_psd','upl_peak_prom','dwl_num_peak','dwl_peak_prom','resolution']]\n",
    "#training = training[['dwl_max_psd','upl_max_psd','dwl_peak_prom','upl_peak_prom','dwl_num_peak','dwl_bytes_avg','upl_bytes_std','upl_bytes_avg','resolution']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dwl_peak_freq</th>\n",
       "      <th>dwl_peak_prom</th>\n",
       "      <th>dwl_max_psd</th>\n",
       "      <th>dwl_bytes_avg</th>\n",
       "      <th>dwl_bytes_std</th>\n",
       "      <th>dwl_peak_avg</th>\n",
       "      <th>dwl_peak_std</th>\n",
       "      <th>upl_peak_freq</th>\n",
       "      <th>upl_peak_prom</th>\n",
       "      <th>upl_max_psd</th>\n",
       "      <th>upl_bytes_avg</th>\n",
       "      <th>upl_bytes_std</th>\n",
       "      <th>upl_peak_avg</th>\n",
       "      <th>upl_peak_std</th>\n",
       "      <th>dwl_time_peak</th>\n",
       "      <th>dwl_num_peak</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>3.498658e+05</td>\n",
       "      <td>3.441002e+05</td>\n",
       "      <td>72271.795699</td>\n",
       "      <td>256539.110163</td>\n",
       "      <td>740.571429</td>\n",
       "      <td>1057.401783</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>12923.219670</td>\n",
       "      <td>12150.389735</td>\n",
       "      <td>3766.440860</td>\n",
       "      <td>10379.952163</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1001.528082</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>2.838183e+05</td>\n",
       "      <td>2.501136e+05</td>\n",
       "      <td>83451.321839</td>\n",
       "      <td>316051.124807</td>\n",
       "      <td>1380.166667</td>\n",
       "      <td>963.684322</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>12377.000916</td>\n",
       "      <td>10827.771453</td>\n",
       "      <td>4115.344828</td>\n",
       "      <td>12564.890968</td>\n",
       "      <td>1380.166667</td>\n",
       "      <td>963.684322</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>3.503755e+05</td>\n",
       "      <td>3.430110e+05</td>\n",
       "      <td>74871.558140</td>\n",
       "      <td>271623.742644</td>\n",
       "      <td>980.000000</td>\n",
       "      <td>1038.429006</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>13348.023387</td>\n",
       "      <td>12677.011516</td>\n",
       "      <td>3696.953488</td>\n",
       "      <td>10854.020391</td>\n",
       "      <td>980.000000</td>\n",
       "      <td>1038.429006</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.336735</td>\n",
       "      <td>3.230138e+05</td>\n",
       "      <td>3.209500e+05</td>\n",
       "      <td>88509.135135</td>\n",
       "      <td>284640.334331</td>\n",
       "      <td>1040.166667</td>\n",
       "      <td>901.514728</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>13571.342361</td>\n",
       "      <td>13239.819300</td>\n",
       "      <td>4347.527027</td>\n",
       "      <td>11384.471692</td>\n",
       "      <td>1040.166667</td>\n",
       "      <td>901.514728</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>3.487811e+05</td>\n",
       "      <td>3.236499e+05</td>\n",
       "      <td>49942.650485</td>\n",
       "      <td>191380.472816</td>\n",
       "      <td>620.166667</td>\n",
       "      <td>893.730462</td>\n",
       "      <td>0.196891</td>\n",
       "      <td>16734.177901</td>\n",
       "      <td>14314.387074</td>\n",
       "      <td>9844.368932</td>\n",
       "      <td>50788.781600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>1.097268e+06</td>\n",
       "      <td>1.043545e+06</td>\n",
       "      <td>253738.413043</td>\n",
       "      <td>580189.681359</td>\n",
       "      <td>902.500000</td>\n",
       "      <td>585.807349</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>53262.247600</td>\n",
       "      <td>52123.889925</td>\n",
       "      <td>13293.500000</td>\n",
       "      <td>27622.507815</td>\n",
       "      <td>902.500000</td>\n",
       "      <td>585.807349</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>9.765048e+05</td>\n",
       "      <td>8.906232e+05</td>\n",
       "      <td>217527.819444</td>\n",
       "      <td>516862.726467</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>1309.223625</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>46129.569359</td>\n",
       "      <td>41808.893237</td>\n",
       "      <td>11329.333333</td>\n",
       "      <td>24669.122888</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>1309.223625</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>5.251847e+05</td>\n",
       "      <td>4.571161e+05</td>\n",
       "      <td>229211.126437</td>\n",
       "      <td>575108.238130</td>\n",
       "      <td>921.600000</td>\n",
       "      <td>904.036526</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>25874.543373</td>\n",
       "      <td>24163.202914</td>\n",
       "      <td>11889.528736</td>\n",
       "      <td>27504.462558</td>\n",
       "      <td>921.600000</td>\n",
       "      <td>904.036526</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.438776</td>\n",
       "      <td>8.523427e+05</td>\n",
       "      <td>8.051908e+05</td>\n",
       "      <td>221431.108108</td>\n",
       "      <td>578239.976452</td>\n",
       "      <td>435.125000</td>\n",
       "      <td>414.244927</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>40051.038123</td>\n",
       "      <td>37570.814535</td>\n",
       "      <td>11485.864865</td>\n",
       "      <td>27438.619912</td>\n",
       "      <td>435.125000</td>\n",
       "      <td>414.244927</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>1.039235e+06</td>\n",
       "      <td>9.816971e+05</td>\n",
       "      <td>212427.789474</td>\n",
       "      <td>514930.758124</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>515.193599</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>48369.683326</td>\n",
       "      <td>45681.858790</td>\n",
       "      <td>11053.578947</td>\n",
       "      <td>24536.179618</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>515.193599</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dwl_peak_freq  dwl_peak_prom   dwl_max_psd  dwl_bytes_avg  dwl_bytes_std  \\\n",
       "0         0.030303   3.498658e+05  3.441002e+05   72271.795699  256539.110163   \n",
       "1         0.130000   2.838183e+05  2.501136e+05   83451.321839  316051.124807   \n",
       "2         0.030151   3.503755e+05  3.430110e+05   74871.558140  271623.742644   \n",
       "3         0.336735   3.230138e+05  3.209500e+05   88509.135135  284640.334331   \n",
       "4         0.030769   3.487811e+05  3.236499e+05   49942.650485  191380.472816   \n",
       "..             ...            ...           ...            ...            ...   \n",
       "218       0.100503   1.097268e+06  1.043545e+06  253738.413043  580189.681359   \n",
       "219       0.092308   9.765048e+05  8.906232e+05  217527.819444  516862.726467   \n",
       "220       0.183673   5.251847e+05  4.571161e+05  229211.126437  575108.238130   \n",
       "221       0.438776   8.523427e+05  8.051908e+05  221431.108108  578239.976452   \n",
       "222       0.092784   1.039235e+06  9.816971e+05  212427.789474  514930.758124   \n",
       "\n",
       "     dwl_peak_avg  dwl_peak_std  upl_peak_freq  upl_peak_prom   upl_max_psd  \\\n",
       "0      740.571429   1057.401783       0.282828   12923.219670  12150.389735   \n",
       "1     1380.166667    963.684322       0.130000   12377.000916  10827.771453   \n",
       "2      980.000000   1038.429006       0.060000   13348.023387  12677.011516   \n",
       "3     1040.166667    901.514728       0.061224   13571.342361  13239.819300   \n",
       "4      620.166667    893.730462       0.196891   16734.177901  14314.387074   \n",
       "..            ...           ...            ...            ...           ...   \n",
       "218    902.500000    585.807349       0.100000   53262.247600  52123.889925   \n",
       "219    882.000000   1309.223625       0.092308   46129.569359  41808.893237   \n",
       "220    921.600000    904.036526       0.183673   25874.543373  24163.202914   \n",
       "221    435.125000    414.244927       0.122449   40051.038123  37570.814535   \n",
       "222    625.000000    515.193599       0.092784   48369.683326  45681.858790   \n",
       "\n",
       "     upl_bytes_avg  upl_bytes_std  upl_peak_avg  upl_peak_std  dwl_time_peak  \\\n",
       "0      3766.440860   10379.952163    800.000000   1001.528082      36.000000   \n",
       "1      4115.344828   12564.890968   1380.166667    963.684322      36.500000   \n",
       "2      3696.953488   10854.020391    980.000000   1038.429006      35.000000   \n",
       "3      4347.527027   11384.471692   1040.166667    901.514728      34.500000   \n",
       "4      9844.368932   50788.781600      1.000000      0.000000      -1.000000   \n",
       "..             ...            ...           ...           ...            ...   \n",
       "218   13293.500000   27622.507815    902.500000    585.807349      10.500000   \n",
       "219   11329.333333   24669.122888    882.000000   1309.223625      10.400000   \n",
       "220   11889.528736   27504.462558    921.600000    904.036526      13.333333   \n",
       "221   11485.864865   27438.619912    435.125000    414.244927       8.428571   \n",
       "222   11053.578947   24536.179618    625.000000    515.193599      10.714286   \n",
       "\n",
       "     dwl_num_peak resolution  \n",
       "0             2.0       240p  \n",
       "1             3.0       240p  \n",
       "2             3.0       240p  \n",
       "3             3.0       240p  \n",
       "4             1.0       240p  \n",
       "..            ...        ...  \n",
       "218           9.0      1080p  \n",
       "219           6.0      1080p  \n",
       "220           7.0      1080p  \n",
       "221           8.0      1080p  \n",
       "222           8.0      1080p  \n",
       "\n",
       "[223 rows x 17 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training.drop(columns=['resolution']), training['resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "#classifier = RandomForestClassifier(n_estimators = 100, criterion = 'gini', random_state = 42)\n",
    "classifier.fit(X_train, y_train)\n",
    "#classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1080p', '720p', '720p', '1080p', '720p', '720p', '1080p', '1080p',\n",
       "       '1080p', '1080p', '1080p', '720p', '720p', '1080p', '720p', '720p',\n",
       "       '1080p', '720p'], dtype=object)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN ON TEST DATA\n",
    "\n",
    "#low_test = pd.read_csv('../data/test/sgs008-109-action-1080p-20210202.csv')\n",
    "#low_test = pd.read_csv('../data/test/sgs008-109-action-720p-20210213.csv')\n",
    "#low_test = pd.read_csv('../data/test/stdoan-102-action-720p-20201206.csv')\n",
    "\n",
    "\n",
    "low_feat = create_features([low_test], 100)\n",
    "\n",
    "test_low = low_feat#[['dwl_max_psd','upl_max_psd','dwl_peak_prom','upl_peak_prom','dwl_num_peak','dwl_bytes_avg','upl_bytes_std','upl_bytes_avg']]\n",
    "y_pred = classifier.predict(test_low)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR VALIDATION SET\n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Group</th>\n",
       "      <th>1080p</th>\n",
       "      <th>240p</th>\n",
       "      <th>360p</th>\n",
       "      <th>480p</th>\n",
       "      <th>720p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1080p</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240p</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360p</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480p</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720p</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Group  1080p  240p  360p  480p  720p\n",
       "Actual Group                                  \n",
       "1080p               11     0     0     1     0\n",
       "240p                 0     4     1     0     0\n",
       "360p                 0     2     7     1     1\n",
       "480p                 0     0     1    16     1\n",
       "720p                 2     0     0     0     8"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.crosstab(y_test, y_pred, rownames=['Actual Group'], colnames=['Predicted Group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88      , 0.72727273, 0.7       , 0.88888889, 0.8       ])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['dwl_bytes_avg','dwl_peak_prom','upl_bytes_std','dwl_bytes_std','upl_peak_std']\n",
    "# importances = classifier.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# for i in indices:\n",
    "#     print(features[i],': ',importances[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['dwl_bytes_avg','upl_max_psd','dwl_max_psd','upl_peak_prom','dwl_num_peak','dwl_peak_prom']\n",
    "# importances = classifier.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# for i in indices:\n",
    "#     print(features[i],': ',importances[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upl_max_psd :  0.11778561076842109\n",
      "dwl_bytes_avg :  0.10960748105793466\n",
      "upl_peak_prom :  0.10182601757952935\n",
      "dwl_peak_prom :  0.09213709181112298\n",
      "dwl_bytes_std :  0.08159211937725258\n",
      "dwl_max_psd :  0.07261900114728903\n",
      "upl_bytes_avg :  0.07162313477015164\n",
      "upl_bytes_std :  0.06717286348384563\n",
      "dwl_num_peak :  0.04902615285964612\n",
      "dwl_time_peak :  0.04877282060674773\n",
      "upl_peak_avg :  0.0472601473539359\n",
      "upl_peak_std :  0.035245518484478794\n",
      "dwl_peak_std :  0.03293344829082329\n",
      "dwl_peak_freq :  0.02739914519803026\n",
      "dwl_peak_avg :  0.026685600206685797\n",
      "upl_peak_freq :  0.018313847004105134\n"
     ]
    }
   ],
   "source": [
    "features = ['dwl_peak_freq','dwl_peak_prom','dwl_max_psd','dwl_bytes_avg','dwl_bytes_std','dwl_peak_avg',\n",
    "            'dwl_peak_std','upl_peak_freq','upl_peak_prom','upl_max_psd','upl_bytes_avg','upl_bytes_std',\n",
    "            'upl_peak_avg','upl_peak_std','dwl_time_peak','dwl_num_peak']\n",
    "importances = classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in indices:\n",
    "    print(features[i],': ',importances[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing that feature method functions correctly\n",
    "\n",
    "# l_start = 0 \n",
    "# l_end = 60\n",
    "\n",
    "# test_chunk = stdoan_low.copy()\n",
    "# test_chunk['Time'] = test_chunk['Time'] - test_chunk['Time'].min()\n",
    "# low_chunk = stdoan_low[(stdoan_low['Time'] >= 0) & (stdoan_low['Time'] < 60)]\n",
    "\n",
    "# low_chunk_ms = convert_ms_df(low_chunk, True)\n",
    "\n",
    "# upl_ms = low_chunk_ms[low_chunk_ms['pkt_src'] == '1']\n",
    "# dwl_ms = low_chunk_ms[low_chunk_ms['pkt_src'] == '2']\n",
    "\n",
    "# dwl_chunk_rs = dwl_ms.resample('500ms', on='Time').sum()\n",
    "\n",
    "# f_dwl, Pxx_dwl = sp.signal.welch(dwl_chunk_rs['pkt_size'], fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
